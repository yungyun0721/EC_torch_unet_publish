{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import create_model_by_experiment_path_and_stage\n",
    "import torch\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preparing...\n",
      "finish 2023------------------\n",
      "finish data loading-----------------\n",
      "test year: ['2023'] numbers: 2952\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_data_folder = '/wk1/bcw817/data/Himawari-8/data_ready/Pacific/'\n",
    "label_data_folder = '/wk1/bcw817/data/Himawari-8/data_ready_qperr/Pacific/'\n",
    "data_channel = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "print('data preparing...')\n",
    "\n",
    "def remove_outlier_and_nan(numpy_array, upper_bound=1000):\n",
    "    numpy_array = np.nan_to_num(numpy_array, copy=False)\n",
    "    # numpy_array[numpy_array > upper_bound] = 0\n",
    "    return numpy_array\n",
    "# load and combine data\n",
    "combine_time_data  = []\n",
    "test_year = ['2023']\n",
    "for year_i in test_year:\n",
    "    input_files = os.listdir(input_data_folder+year_i)\n",
    "    input_files.sort()\n",
    "    for file in input_files:\n",
    "        input_tmp = nc.Dataset(input_data_folder+year_i+'/'+file)\n",
    "        time_tmp = input_tmp.variables['time'][:]+np.int_(file[2:-3])*1000\n",
    "        time_tmp = list(map(str, time_tmp))\n",
    "        input_data = input_tmp.variables['Himawari_images'][:]\n",
    "        label_tmp = nc.Dataset(label_data_folder+year_i+'/'+file)\n",
    "        label_data = label_tmp.variables['qperr'][:]\n",
    "        if year_i == test_year[0] and file == input_files[0]:\n",
    "            combine_input_data = input_data\n",
    "            combine_label_data = label_data\n",
    "        else:\n",
    "            combine_input_data = np.concatenate((combine_input_data, input_data), axis=0)\n",
    "            combine_label_data = np.concatenate((combine_label_data, label_data), axis=0)\n",
    "        combine_time_data = combine_time_data+time_tmp\n",
    "    print(f'finish {year_i}------------------')\n",
    "print('finish data loading-----------------')\n",
    "data_channel = [data_channel_index-1 for data_channel_index in data_channel]\n",
    "combine_input_data = remove_outlier_and_nan(combine_input_data)[:,:-1,:,:][:,:,:-1,:][:,:,:,data_channel]\n",
    "combine_label_data = remove_outlier_and_nan(combine_label_data)[:,:-1,:,:][:,:,:-1,:]\n",
    "\n",
    "print(f\"test year: {test_year} numbers: {len(combine_time_data)}\")\n",
    "combine_time_data = list(map(float, combine_time_data))\n",
    "combine_time_data = list(map(int, combine_time_data))\n",
    "\n",
    "# size:［B, C, H, W］\n",
    "input_data_test  = np.swapaxes(np.swapaxes(combine_input_data,2,3),1,2)\n",
    "label_data_test  = np.swapaxes(np.swapaxes(combine_label_data,2,3),1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "experiment_path = '/wk171/yungyun/for_gitea_publish/EC_torch_unet_publish/experiments/downscaling_unet_test.yml'\n",
    "sub_exp_name = 'unet_try1'\n",
    "model_name, weight_path = create_model_by_experiment_path_and_stage(experiment_path, sub_exp_name)\n",
    "new_input_data_test = torch.from_numpy(input_data_test.astype('float32'))\n",
    "\n",
    "# load on gpu or cpu\n",
    "new_input_data_test = new_input_data_test.to(device)\n",
    "model_name = model_name.to(device)\n",
    "model_name.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "pred_rainfall = label_data_test*0.0\n",
    "\n",
    "# evaluate\n",
    "model_name.eval()\n",
    "for i in range(len(pred_rainfall[:,0,0,0])):\n",
    "    pred_rainfall[i,0,:,:] = model_name(new_input_data_test[i:i+1,:,:,:])[0,0,:,:].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2952, 1, 100, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rainfall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/1004/ipykernel_15368/343249998.py:82: UserWarning: The following kwargs were not used by contour: 'linesytles'\n",
      "  filled_c = ax1.contourf(lons, lats, input_data, levels=np.linspace(200,300,21),cmap='gray',linesytles=None)\n",
      "/tmp/user/1004/ipykernel_15368/343249998.py:92: UserWarning: The following kwargs were not used by contour: 'linesytles'\n",
      "  filled_c = ax2.contourf(lons, lats, preds_data, levels=clevel, norm=norm,cmap=precip_colormap,linesytles=None)\n",
      "/tmp/user/1004/ipykernel_15368/343249998.py:104: UserWarning: The following kwargs were not used by contour: 'linesytles'\n",
      "  filled_c = ax3.contourf(lons, lats, label_data, levels=clevel, norm=norm,cmap=precip_colormap,linesytles=None)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov  4 15:44:58 2021\n",
    "\n",
    "@author: yungyun\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#%% plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "coast = pd.read_csv('/wk171/yungyun/AI_global_model/Pangu-Weather-for-copy/plot/coast.csv')\n",
    "\n",
    "\n",
    "#%% rain setting\n",
    "nws_precip_colors = [\n",
    "    \"#fdfdfd\",  # 0.01 - 0.10 inches\n",
    "    \"#c9c9c9\",  # 0.10 - 0.25 inches\n",
    "    \"#9dfeff\",\n",
    "    \"#01d2fd\",  # 0.25 - 0.50 inches\n",
    "    \"#00a5fe\",  # 0.50 - 0.75 inches\n",
    "    \"#0177fd\",  # 0.75 - 1.00 inches\n",
    "    \"#27a31b\",  # 1.00 - 1.50 inches\n",
    "    \"#00fa2f\",  # 1.50 - 2.00 inches\n",
    "    \"#fffe33\",  # 2.00 - 2.50 inches\n",
    "    \"#ffd328\",  # 2.50 - 3.00 inches\n",
    "    \"#ffa71f\",  # 3.00 - 4.00 inches\n",
    "    \"#ff2b06\",\n",
    "    \"#da2304\",  # 4.00 - 5.00 inches\n",
    "    \"#aa1801\",  # 5.00 - 6.00 inches\n",
    "    \"#ab1fa2\",  # 6.00 - 8.00 inches\n",
    "    \"#db2dd2\",  # 8.00 - 10.00 inches\n",
    "    \"#ff38fb\",  # 10.00+\n",
    "    \"#ffd5fd\"]\n",
    "\n",
    "\n",
    "precip_colormap = mpl.colors.ListedColormap(nws_precip_colors)\n",
    "item = 18\n",
    "clevel = [0, 0.5, 1, 2, 6, 10, 15, 20,  30, 40, 50,\n",
    "          70, 90, 110, 130,150,200,300,400]\n",
    "norm = mpl.colors.BoundaryNorm(clevel, item)\n",
    "\n",
    "# for case_i in range(len(test_index)):\n",
    "for case_i in range(2):\n",
    "        # case_i = 20\n",
    "        input_data = input_data_test[case_i,13,:,:]\n",
    "        preds_data = pred_rainfall[case_i,0,:,:]\n",
    "        label_data = label_data_test[case_i,0,:,:]\n",
    "        \n",
    "        \n",
    "        font = {'family'     : 'DejaVu Sans Mono',\n",
    "                'weight'     : 'bold',\n",
    "                'size'       : 18\n",
    "                }\n",
    "        axes = {'titlesize'  : 18,\n",
    "                'titleweight': 'heavy',\n",
    "                'labelsize'  : 18,\n",
    "                'labelweight': 'bold'\n",
    "                }\n",
    "        mpl.rc('font', **font)  # pass in the font dict as kwargs\n",
    "        mpl.rc('axes', **axes)\n",
    "        #ax.add_geometries(adm1_shapes, ccrs.PlateCarree(),\n",
    "        #                  edgecolor='black', facecolor='gray', alpha=0.5)\n",
    "        # Pracific\n",
    "        latStart = 23; latEnd =24.2375;#25.35\n",
    "        lonStart = 121.875; lonEnd = 123.1125\n",
    "        lat = np.linspace(latStart,latEnd,100)\n",
    "        lon = np.linspace(lonStart,lonEnd,100)\n",
    "        lons, lats = np.meshgrid(lon, lat)    \n",
    "        # lons, lats = np.meshgrid(EC_lon, EC_lat)\n",
    "        plt.figure(figsize=(18,6))\n",
    "        plt.suptitle(combine_time_data[case_i])\n",
    "        plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] \n",
    "\n",
    "        # ax1 = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "        ax1 = plt.subplot(1, 3, 1)\n",
    "        filled_c = ax1.contourf(lons, lats, input_data, levels=np.linspace(200,300,21),cmap='gray',linesytles=None)\n",
    "\n",
    "        ax1.plot(coast.lon_map, coast.lat_map, color='k', linewidth=0.7)\n",
    "        ax1.set_xticks(np.arange(120, 123))\n",
    "        ax1.set_yticks(np.arange(22, 26))\n",
    "        plt.xlim([118, 124])\n",
    "        plt.ylim([21, 26])\n",
    "        ax1.tick_params('both', labelsize=16)\n",
    "\n",
    "        ax2 = plt.subplot(1, 3, 2)\n",
    "        filled_c = ax2.contourf(lons, lats, preds_data, levels=clevel, norm=norm,cmap=precip_colormap,linesytles=None)\n",
    "        ax2.plot(coast.lon_map, coast.lat_map, color='k', linewidth=0.7)\n",
    "        ax2.set_xticks(np.arange(120, 123))\n",
    "        ax2.set_yticks(np.arange(22, 26))\n",
    "        plt.xlim([118, 124])\n",
    "        plt.ylim([21, 26])\n",
    "        ax2.tick_params('both', labelsize=16)\n",
    "        ax2.tick_params('both', labelsize=16)\n",
    "\n",
    "\n",
    "\n",
    "        ax3 = plt.subplot(1, 3, 3)\n",
    "        filled_c = ax3.contourf(lons, lats, label_data, levels=clevel, norm=norm,cmap=precip_colormap,linesytles=None)\n",
    "        ax3.plot(coast.lon_map, coast.lat_map, color='k', linewidth=0.7)\n",
    "        ax3.set_xticks(np.arange(120, 123))\n",
    "        ax3.set_yticks(np.arange(22, 26))\n",
    "        plt.xlim([118, 124])\n",
    "        plt.ylim([21, 26])\n",
    "        ax3.tick_params('both', labelsize=16)\n",
    "        ax3.tick_params('both', labelsize=16)\n",
    "        plt.savefig('plt_test/'+str(combine_time_data[case_i])+'.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146.75"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 1, 112, 104)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_windy_predict"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63b160d859a8a4d63e4749ea4dd5e118a0ddc9e77cbee592cc94db621a8d31d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('EC_downscaling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
